{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff514d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0536bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 17736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes:\n",
    "\"\"\"\n",
    "Irregular: 0\n",
    "Merging: 1\n",
    "Smooth/Round: 2\n",
    "Spiral: 3\n",
    "Edge-On: 4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e02c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/Path/to/File', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e19148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray Scaling\n",
    "\n",
    "gray_images = []\n",
    "for i in range(len(images)):\n",
    "    gray_img = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "    gray_images.append(gray_img)\n",
    "    \n",
    "images = np.array(gray_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images\n",
    "images = images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to 64x64\n",
    "images_resized = np.array([resize(img, (128, 128)) for img in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24529f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing number of classifications\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 3 or labels[i] == 4:\n",
    "        labels[i] = 2\n",
    "    if labels[i] == 5 or labels[i] == 6 or labels[i] == 7:\n",
    "        labels[i] = 3\n",
    "    if labels[i] == 8 or labels[i] == 9:\n",
    "        labels[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a temporary set using the train_test_split function.\n",
    "images_train, images_temp, labels_train, labels_temp = train_test_split(images_resized, labels, test_size=0.3, \n",
    "                                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93cad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the temporary set into a validation set and a test set.\n",
    "images_val, images_test, labels_val, labels_test = train_test_split(images_temp, labels_temp, test_size=0.5, \n",
    "                                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc895c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "input_shape = (128, 128, 1) \n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the labels\n",
    "labels_train_encoded = to_categorical(labels_train)\n",
    "labels_val_encoded = to_categorical(labels_val)\n",
    "labels_test_encoded = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(images_train, labels_train_encoded, \n",
    "                    validation_data=(images_val, labels_val_encoded),\n",
    "                    epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce591e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "loss, accuracy = model.evaluate(images_test, labels_test_encoded)\n",
    "print(\"Test Accuracy: \", accuracy)\n",
    "print(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c382028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New image testing \n",
    "\n",
    "def GalaxyPredict(file):\n",
    "    \n",
    "    # Load the image\n",
    "    img = Image.open(file)\n",
    "    \n",
    "    # Numpy array conversion\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # normalize\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # Resize the image\n",
    "    img = cv2.resize(img, (128, 128))  # Change this line\n",
    "\n",
    "    # Add an extra dimension because the model expects a batch\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "    #Predict galaxy\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    print(\"The predicted class is:\", predicted_class)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "GalaxyPredict('/Path/to/Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60332cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e2952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnenv",
   "language": "python",
   "name": "nnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
